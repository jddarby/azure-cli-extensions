global:

  #dafault rbac clusterrole and serviceaccount configuration
  defaultRbacEnabled: true
  defaultClusterRole: permissive-network-cr
  defaultServiceAccountName: fed-elastic-serviceaccount

  #Generic password for all PAAS components
  adminPassword: ""

  podPriorityEnabled: true

  # Fluentd Configurations
  logging:
    enabled: false
    fluentd:
      buffer:
        bufferLimit: 512m  # Total buffer size. Maximum amount of buffer space each fluentd thread would use to keep logs. After this is exhaused, fluentd would start deleting oldest logs to make room for new logs.
        retryWait: 180s    # Interval(seconds) at which the buffer flush is retried in case of failure.
        maxRetries: 10     # Max number of retries to flush a buffer chunk. After this is exhausted, fluentd would delete the chunk.
    elastic:
      IP: ""
      Port: 9200
    enableAddlTargets: false
    addlTargets:
    - forward:
        name: fluentd
        host: ""
        port: 24224
    alerts:
      enabled: false
      host: ""
      port: 3030
      realert:
        minutes: 1
      # Multiple receivers can be configured under the below receivers section. For example: if another slack reciever is to be configured,
      # then add another list item for slack by following the syntax as shown below. Currently 3 types of receivers are supported i.e slack, email and HTTP POST.
      receivers:
        - slack:
            webhookurl: ""
        - post:
            http_post_url: ""
        - email:
            to_address: ""
            smtp_host: ""
            smtp_port: ""
            smtp_ssl: false
            from_addr: ""

  vault:
    enabled: false
    hashicorpVault:
      enabled: true
      service: "http://fed-vault-svc-internal.fed-vault:8200" # DevSkim: ignore DS137138
    azureKeyVault:
      enabled: false
  
  # This enables collection of elastic server statistics data by kargo 
  kargoProfileTag: "elastic"      
  
   # NetworkPolicy Configuration
  ingressNetworkPolicy:
    # enabled: true -> enables networkpolicy in federation, false -> disables networkpolicy in federation
    enabled: true
    # Namespaces which are required to be allowed for ingress traffic
    ingressTrafficNamespaces:
    - fed-paas-helpers
    - fed-jaeger
    - fed-kubedb-operator
    - fed-prometheus

  grafana:
    enabled: true
    # If Grafana is enabled, please add a valid Grafana server URL as per the following guidelines.
    # If Grafana is deployed WITHOUT TLS: "http://[grafana-ip]:[grafana-port]" OR "http://[paas-lb-ip]:[grafana-port]" (by-default grafana-port is 3000)
    # If Grafana is deployed WITH TLS: "https://[grafana-ip]:[grafana-port]" OR "https://[paas-lb-ip]:[grafana-port]" (by-default grafana-port is 3000)
    url: ""
    prometheusinfo:
      url: "http://prometheus.fed-prometheus:9090" # DevSkim: ignore DS137138

  # Prometheus metrics scrape intrval. Default value set to 1m.
  metricsScrapeInterval: 1m
 
  # PaaS Registry Selector
  registry:
    docker:
      repoPath:       "a4oprodaf.a4opacketcore.microsoft.com/rel_build_docker"

  # Environment variables
  envVars:
    fedType:        "paas"
    fedUniqueName:  "elastic-default"

  #specify the IP ranges that are allowed to access the load balancer
  loadBalancerSourceRanges: ""

  overrides:
    postInstallEnabled: false
    preDeleteEnabled: false

pod-elastic:  
  # elastic Search version represents which version to be installed, check supported version by executing
  # kc get elasticsearchversions
  elasticVersion: 7.10.2-searchguard

  # To run elasticserach on a single node, enable singleNodeElastic.enabled=true and set the required resource request and limit 
  singleNodeElastic: 
    enabled: false
    resources:
      request:
        memory: "1Gi"
        cpu: "450m"
      limit:
        memory: "1Gi"
        cpu: "1100m"

  # Configure below section for multi node elastic  
  replicas:
    master: 3
    data: 3
    client: 2

  externalStorage:
    # type can be local, remote or rook
    type: local
    # To use storage class of fed-rook-ceph, Configure storageclass field with the storage class name that gets deployed with fed-rook-ceph.
    # default value is "rook-cephbp". To use any other storage provisioner provide name of your convienence.
    storageClassName: cinder-class
    # if storage.type is set as rook, Configure storageclass and do not configure the below mentioned fields. When type is rook, provisioner and all the other 
    # configuration parameters will be taken from storage class of fed-rook-ceph.
    # set provisioner as:
    # kubernetes.io/cinder for cinder storage
    # kubernetes.io/azure-disk for azureDisk
    # To provide any other custom storage, configure provisioner field and add related parameters under customParameters
    provisioner: kubernetes.io/cinder
    parameters:
      cinder:
        type: ceph
        availability: nova
        fsType: ext4
      azureDisk:
        storageaccounttype: ""
        kind: ""
      #configure below customParameters to provide parameters for custom storage option, if the provisioner is none of the above.  
      customParameters: {}
    #PersistentVolumes that are dynamically created by a StorageClass will have the reclaim policy specified in the reclaimPolicy field of the class, which can be either Delete or Retain
    reclaimPolicy: Delete
    allowVolumeExpansion: true
    # storage allocation for each type of elastic pod, Data pod stores data so more Size should be specified
    # The storage size of data nodes would also depend on the number of replicas configured per index as part of fed-paas-helpers,
    # If replica is set to 1, the storage requirement becomes double as ES would maintain a duplicate set of data.
    storageSize:
      master: 8Gi
      client: 8Gi
      data: 150Gi

  # Give resource requirements for each type of pod
  resources:
    master:
      request:
        memory: "8Gi"
        cpu: "1"
      limit:
        memory: "15Gi"
        cpu: "3"
    client:
      request:
        memory: "8Gi"
        cpu: "2"
      limit:
        memory: "15Gi"  
        cpu: "5"
    data:
      request:
        memory: "10Gi"
        cpu: "2"
      limit:
        memory: "20Gi"
        cpu: "5"

  # rbacEnabled, serviceAccountName configuration for pod-elastic: These configuration is used to create the rolebinding and serviceaccount.
  # Configuring rbacEnabled to true will create customrole, customrolebinding. Configuring rbacEnabled to false, customrole,customrolebinding will not be created.
  rbacEnabled: true
  # serviceAccountName configuration is used to create serviceaccount per pod.
  serviceAccountName: "elastic-serviceaccount"
  
  # exposedIp is the ip address exposed by elasticsearch
  service:
    exposedPort: 9200
    loadBalancer:
      # metallb will automatically assign EXTERNAL-IP for service type=LoadBalancer.
      loadBalancerIP: ""
      loadBalancerFQDN: ""
      # sharing key is for having single loadbalancer IP shared among multiple paas components.
      loadBalancerSharingKey: "paas"
      serviceAnnotations:
        service.beta.kubernetes.io/azure-load-balancer-internal: "true"
        service.beta.kubernetes.io/azure-load-balancer-internal-subnet: "none"
 
  # temination policy, More details https://kubedb.com/docs/0.10.0/concepts/databases/elasticsearch/#spec-terminationpolicy
  terminationPolicy: "Delete"

  ## Elastic specific configurations, 
  # Default thread bulk queue size is 200
  threadPoolBulkQueueSize: 10000

  healthCheck:
    failureThreshold: 3
    periodSeconds: 10
    timeoutSeconds: 10

  redeployer:
    enabled: true
    periodSeconds: 60
    failureThreshold: 5
  
  ## Curator Configuration for purging old logs
  curator:
    cron:
      schedule: "\"*/10 * * * *\""  ## Cron shceduler, every 10 minutes curator will run and clean elastic search 
      startingDeadLineSeconds: 300  # After Helm deployment, curator will start after 5 minutes. In 5 minutes it is expected that elastic deployed successfully
    config:
      deleteLogs:
        timeBased:
          unitForLogs: days
          unitCountForLogs: 3  ## delete elastic indices which are older than 3 days with pattern fluentd* which is used for logs sent by fluentd
          unitForJaegerSpan: days
          unitCountForJaegerSpan: 3  ## delete elastic indices which are older than 3 days with pattern jaeger-span* which is used for spans sent by jaeger
        sizeBased:
          totalDiskUsage: 1000 ## Delete index based on the total configured disk size threshold, starting with the oldest indices, based on index creation_date.
          sizeLogs: 100 ## delete fluentd logs indices so that total disk size is within 200GB.
          sizeJaegerSpan: 100 ## delete jaeger span indices so that total disk size is within 200GB.
